# Database Normalization with PostgreSQL

## Introduction to Normalization

Normalization is the process of restructuring the data of a database for optimization. In academic setting the "normal forms" of a database are discussed using the first normal form, second normal form and third normal form (1NF, 2NF, 3NF). These technical names and definitions aren't used much in the field, but can be helpful to know.

## Duplicated Data

Avoid duplicating data anywhere in the database, while still keeping the relationships of the data between tables.

In general, if a column in your database does not depend on, or describe its primary key, then it is likely duplicated.

## Data Update Challenges

When data is duplicated, that means that we would have to update that data everywhere that it occurs, rather than just in a single record. You might think this would be easy to do as long as we can use a `WHERE` clause, however, multiple records that represent different things can have matching values in columns as well, making this challenging.

We could have tried to enforce `UNIQUE` or `PRIMARY KEY` constraints, but if everything is stored in one table, then we won't be able to accommodate the fact that values will have to be duplicated.

## Data Insertion Challenges

If we're storing all of the information in one table, then when we go to insert a record, if we don't have the data for the primary key then we won't be able to insert a record.

For example: if a college's information was all stored in one table, imagine that a new advisor was hired, but not assigned any students. There would be no way to add this advisor to the database if the student id was used as the primary key.

## Search and Sort Efficiency

Now imagine trying to keep track of accurate information in a many-to-many relationship. If we were going to try and get information on how many students had a particular major, we would wind up with incomplete information, since a student could have two majors. We couldn't just cound the `major_1` column, we'd also have to count `major_2` , this means that we'd have to join the columns together somehow creating complexity.

## Restructuring Columns

If we have a non-normalized database, we can begin to normalize this data by creating a new table with the information that is duplicated across the database by selecting those columns and their distinct values:

```sql
CREATE TABLE majors AS
SELECT distinct major_1, major_1_credits_reqd
FROM college;
```

Once this is done, the columns in the new table can be removed from the old:

```sql
ALTER TABLE college
DROP COLUMN major_1,
DROP COLUMN major_1_credits_reqd;
```

## Creating Versus Modifying a Database Schema

It is preferable to create a normalized schema from the beginning. Moving columns and modifying data, though it will have to happen, introduces a level of complexity, and the risk of data loss.

## Database Structure and Use

There is no universal correct way to create a database. For example, if a column or table in a database is never going to be modified, it doesn't matter as much if there is duplicated data.

The tradeoff for normalization of data in a database is that some queries may actually become more complex to perform. When data is spread across multiple tables, queries about relationships may involving the joining of two or three tables back together. Usually this tradeoff is worth it to maintain data integrity and a simple database schema.

