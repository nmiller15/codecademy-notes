# Deadlocks

## What is Deadlock?

For a synchronization we will likely need to lock critical sections of our code to guarantee that only one thread at a time enters our program. This fulfils the problem of mutual exclusion, but we must also have progress and bounded waiting.

Bounded waiting is the concept that each thread that asks permission to endter a critical section will in fact get there. If a request is starved and there are multiple locks that don’t release the critical sections, *deadlock* can occur.

## Causes of Deadlocks

When two threads lock a mutex and then wait on one another to open before continuing, they are in deadlock. This means that the program cannot proceed. Here’s an example:

| **thread_1**    | **thread_2**    |
| --------------- | --------------- |
| lock(foo_mtx)   | lock(bar_mtx)   |
| lock(bar_mtx)   | lock(foo_mtx)   |
| Do something    | Do something    |
| unlock(foo_mtx) | unlock(bar_mtx) |
| unlock(bar_mtx) | unlock(foo_mtx) |

These two threads will never proceed into the “Do something” step because the mutex they are trying to lock in the second step cannot be locked because the other thread already has locked it. Neither will receive this lock

## Prevention and Recovery

The best way to avoid deadlocks is to only implement programs in  a way that deadlocks cannot happen, however, programs will get complex and the number of critical sections across many threads may make this difficult to track.

We can recover a deadlock through *termination*. When we terminate a thread that is in deadlock, we release its locks and allow other threads to proceed, however, we will lose any of the work that this thread has done. If it was completeing an important task, this may now be delayed, or may never happen.

We can also recover a deadlock through releasing a lock instead of terminating the thread. This way the thread is not terminated, but, we can no longer guarantee mutual exclusion, which creates another synchronization problem.

