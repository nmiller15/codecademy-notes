# Memory Management

## What is Memory Management?

This is the concept that the operating system must choose what information to store and where it should be stored. The CPU has choices on where that memory can go and makes those decisions based on how soon that information will be needed, how often it will be needed, how long it will be needed and how quickly it will need to be accessed.

Computer memory is limited, like other physical storage, so memory must be managed efficiently.

## The Memory Hierarchy

Memory can be ordered by size and distance from the processor. As we get further away from the processor, the memory gets larger but it also gets slower as we go.

There are four main types of memory: **registers, caches, main and disk**.

Registers are the closest to the processor and are the fastest and smallest. They only really store computational values that are being worked on by the processor *right now*.

Caches are a staging ground for datat that the processor will need in the immediate future. This information could also be stored in main memory, but frequently used data will be storead and accessed from here since it’s faster than going to main.

Main memory, or RAM, is the larger and slower than the cache, but works on largerly the same thing. Here is where the data and instructions the processor is currently working on are stored. This is a temporary information store, so it will lose all data once it has lost power.

The disk is large, and it is slow. This is where information that needs to be permenantly stored goes. Operations like retrieving or searching files on a disk will be much slower since writing to and reading from them takes longer than other memory.

## Segmentation

In our different memory types, there are also different ways of storing information in memory.

The simplest way to store information in memory is through *segmentation*. This is where, if a piece of information needs to be stored a process will request an amount of memory - a certain amount of bits (0s and 1s). Then, the process will have to wait for a contiguous block of memory to be free, found and then allocated to the process.

## Fragmentation

Segmentation stores process data in adjacent, sequential, back-to-back memory. This means that if there’s 30 MB of free memory in 2 15MB chunks, and a process requests 20MB, it will have to wait for another process to end and free up that memory so that it can access 20 sequential MB.

This is called fragmentation and it is the big disadvantage to segmentation.

## Virtual Memory and Privilege Separation

It’s important that we segment memory for different processes. Consider that both the kernel and the operating system must operate in memory. So we must keep the kernel processes separate from user-space (or non-kernel processes). If these were to conflict, kernel processes could be corrupted and the whole computer could stop working. We should also keep user processes segmented from one another so that they don’t corrupt one another.

We can segment our phsical memory into virtual memory. This is a virtualization that allows us to offer a segment of our physical memory to a process, and the process can behave as if that is the entire available memory.

Virtual memory can map to physcial memory in noncontiguous chunks while still presenting contiguous chunks to the processes using them.

## Paging

A way to solve the contiguous information problem of fragmentation is through paging. This is where data is stored in blocks of memory of equal size called pages. This means that the space between each page of free memory will never change.

We can store these pages of data non-contiguously and using virtualization we can offer then to the OS or processes seemingly contiguously.

## Linkers and Loaders

Before a program can be run, we must *link* and *load* it.

Most programs have many dependencies that are needed in order to run correctly. A *linker*'s job is to connect our program with all of these dependencies. It does this by creating an *executable file*. This is a file that, when opened, can be used to actually run our program.

The the executable is run, the first step of execution is called *loading*. This is where a *loader* takes the instructions on runnin gthe program and moves that into main memeory to be run.

Both linking and loading can be done statically or dynamically. Static linking is where dependencies are all linked up front, and dynamic linking is where the dependencies are linked at runtime when they are needed. This allows our OS to see if some of the dependencies are already running in memory before linking with them again.

Static loading is where the entirety of the program and dependencies are loaded into memory at execution time. Dynamic loading is where the OS only loads the parts that are needed into memory.

Dynamic linking and loading are far more efficient with memory usage, while static linking and loading tend to execute faster because there is no runtime getching of dependencies once the program is running.

