# Process Scheduling

## Processing States and Queues

When multiple processes are waiting to use the same resouces, they may do this in the `Ready` state or the `Blocked` state. They also will typically wait in a *queue*. A queue is a first-in first-out data structure. The processes will be executed in order of the request. However, sometimes processes need to be executed first, becasue they are vital system resources, or they must be accomplished at a speicifc time. This is where a *priority queue* can be used. This will sort the processes by importance, having the highest priority item always be executed first rather than the order of the request. There is a scheduling alogrithm that assigns integer values or categories to each process, defining its priority.

## Long-Term Scheduling

The *long-term scheduler* is the first schedule encountered by a process and determines which of these newly created processes are loaded into memory and admitted into the ready queue. It doesn't run as often as the medium or short term schedulers.

The long-term scheudler has lots of available memory, so it can add many processes to the ready queue allowing interleaving of processes in the CPU which can give the appearance of parallel execution.

## Medium-Term and Short-Term Schedulers

### Short-Term Scheduler

The short-term scheduler passes the process from the Ready queue to the CPU. This scheduler has admit power as well as force recall power through preemption. This is helpful if higher priority processes are added that need to be quickly executed.

The short-term scheduler is the sole maintainer of context switches for processes. It stores and reloads the relevant process information as needed. It can also preempt set time intervals in order to more fairly share the processor and prevetnt a single long-running process from hogging the CPU.

### Medium-term Scheduler

When a process tries to access unavailable resources or is inactive for a prolonged period, the *medium-term* scheduler removes the process from the CPU and frees up the cores to be used by other processes. It will block the process and may move it to a special swap section of the hard drive to free memory.

## First Come First Served

This is the most basic scheduling algorithm. FIFO is subject to the convoy effect, where long processes can occupy the CPU while doing minimal computation. There is also no priority other than time in a queue. This means that buffer time and blocking can be an issue.

It is a very simple algorithm, however, meaning that there is minimal schedling overhead from lack of context switching. And, if we asume that each process eventually completes, then each process should be able to run and not have to “suffer starvation” by never being executed.

## Priority Scheduling Algorithms

Priority scheduling assigns each process a numeric priority before organizing the execution of the priority.

One variation of priority scheduling is “shortest job first,” which schedules the events in ascending order according to the estimated time it will take to execute them. With preemption, there is also a “shortest *remaining* time" that can be used instead. Each time an interruption occurs, the priority will be reevaluated. These only work in situations where the process time can be reasonably and relatively accurately estimated beforehand.

This method will minimize wait times for each process but longer processes may be “stared” and may never execute if shorter processes are continually proritized. This is solved by implementing “aging”, ensuing that the wait time of a process will raise priority as it increases.

Overhead is high, and processes can be arbitrarily interrupted whenever a shorter one is added. The queue also needs to be continually sorted as processes are added, removed or modified.

## Round Robin

This scheduling algorithm creates a fixed amount of execution time (called a *time slice*) and assigns it to each process. It will cycle through all of the processes until they are all completed. If a process does not complete during its time slice, it will be rescheduled to allow other processes a chance to run before attempting again.

This method is a compromise between FIFO and shortest-first. Long jobs will run faster in round robin than in shortest-first, and short jobs will also tend to run faster than in FIFO.

Starvation will never occur in this, since priority is not assigned, and everything is given CPU time. This can lead to lower latency and response times, but waiting times can still be high for an individual process, since a long process may take several rounds to complete.

This algorithm ignores deadlines typically, so for real-time devices, this is probably not the best fit.

The round robin’s scheduling overhead is significant since any time a process doesn’t execute in the time slice, the process must be context switched. This means that the CPU doesn’t have as much utilization for the other processes.

## Multiple-level Queues Scheduling

This algorithm allows for the creation of multiple queues at different priorities. A scheduler on this algorithm will clear the highest-priority queue first, then move to the next and the lowest priority last. The advantage of this algorithm is that each level of the queue can use it’s own algorithm based on what it is handling. This allows you to take advantage of the best qualities of each algorithm while managing different types of processes.

The low-priority level can be subject to starvation if the high- and middle-priorities have processes continually added, since processes will not move between levels in this algorithm.

